@inproceedings{reverb12,
abstract = {Characterization of Zn1-xMnxSe nanowires grown by Au-catalyzed chemical vapor deposition (CVD) using transmission electron microscopy is reported. The nanostructures were found to grow in the form of nanowires, nanoribbons, and nanosaws. The fraction of manganese on the cation sublattice in the nanowires varied from x=0.1 to x=0.28. No correlation between Mn fraction and nanowire diameter was found for straight nanowires; however, in tapered nanowires the Mn fraction was found to increase as the diameter increased. The tapering, as well as the increase in Mn fraction, is likely caused by thin film deposition with a higher Mn fraction on the sides of the nanowires. Some of the nanoribbons were found to display extra diffraction spots at half-order positions in selected area diffraction. The half-order reflections were found to have originated from spontaneous atomic ordering of Mn and Zn on planes on the cation sublattice. {\textcopyright} 2013 Elsevier B.V.},
address = {Edinburgh, UK},
author = {{A. Fader, S. Soderland}, O. Etzioni},
booktitle = {Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
doi = {10.1016/j.jcrysgro.2013.04.025},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/reverb.pdf:pdf},
isbn = {1535-4970},
issn = {00220248},
keywords = {A1. Characterization,A1. Crystal structure,A1. Nanostructures,A1. Transmission electron microscopy,B1. Nanomaterials,B2. Semiconducting ternary compounds},
pages = {1535--1545.},
title = {{Identifying relations for Open Information Extraction}},
url = {},
year = {2011}
}


@article{gate12,
abstract = {In this paper we present GATE, a framework and graphical development environment which enables users to develop and deploy language engineering components and resources in a robust fashion. The GATE architecture has enabled us not only to develop a number of successful applications for various language processing tasks (such as Information Extraction), but also to build and annotate corpora and carry out evaluations on the applications generated. The framework can be used to develop applications and resources in multiple languages, based on its thorough Unicode support.},
author = {Cunningham, Hamish and Maynard, Diana and Bontcheva, Kalina and Tablan, Valentin},
doi = {10.3115/1073083.1073112},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/GATE.pdf:pdf},
isbn = {978-3-540-73350-8},
journal = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics - ACL '02},
pages = {168},
title = {{Gate}},
url = {http://portal.acm.org/citation.cfm?doid=1073083.1073112},
year = {2001}
}
@article{Klein2003,
abstract = {We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36{\%} (LP/LR F1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the-art. This result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized PCFG is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize.},
author = {Klein, Dan and Manning, Christopher D.},
doi = {10.3115/1075096.1075150},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/unlexicalized-parsing.pdf:pdf},
isbn = {1935-5548 (Electronic)$\backslash$r0149-5992 (Linking)},
issn = {00219991},
journal = {Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - ACL '03},
keywords = {stanford12},
pages = {423--430},
pmid = {12855250},
title = {{Accurate unlexicalized parsing}},
url = {http://portal.acm.org/citation.cfm?doid=1075096.1075150},
volume = {1},
year = {2003}
}
@article{aqualog12,
abstract = {As semantic markup becomes ubiquitous, it will become important to be able to ask queries and obtain answers, using natural language (NL) expressions, rather than the keyword-based retrieval mechanisms used by the current search engines. AquaLog is a portable question-answering system which takes queries expressed in natural language and an ontology as input and returns answers drawn from the available semantic markup. We say that AquaLog is portable, because the configuration time required to customize the system for a particular ontology is negligible. AquaLog combines several powerful techniques in a novel way to make sense of NL queries and to map them to semantic markup. Moreover it also includes a learning component, which ensures that the performance of the system improves over time, in response to the particular community jargon used by the end users. In this paper we describe the current version of the system, in particular discussing its portability, its reasoning capabilities, and its learning mechanism.},
author = {Lopez, Vanessa and Pasin, Michele and Motta, Enrico and Hall, Walton and Keynes, Milton},
doi = {10.1007/11431053_37},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/Lopez2005{\_}Chapter{\_}AquaLogAnOntology-PortableQues.pdf:pdf},
isbn = {978-3-540-26124-7},
issn = {03029743},
journal = {In Proceedings of the 2008 Conference on Semantics in Text Processing},
pages = {546--562},
title = {{AquaLog : An Ontology-Portable Question Answering System for the Semantic Web}},
year = {2005}
}
@article{sparklis12,
abstract = {SPARKLIS is a Semantic Web tool that helps users explore and query SPARQL endpoints by guiding them in the interactive building of questions and answers, from simple ones to complex ones. It combines the finegrained guidance of faceted search, most of the expressivity of SPARQL, and the readability of (controlled) natural languages. No knowledge of the vocabulary and schema are required for users. Many SPARQL features are covered: multidimensional queries, union, negation, optional, filters, aggregations, ordering. Queries are verbalized in either English or French, so that no knowledge of SPARQL is ever necessary. All of this is implemented in a portable Web application, SPARKLIS, and has been evaluated on many endpoints and questions. No endpointspecific configuration is necessary as the data schema is discovered on the fly by the tool. Online since April 2014, thousands of queries have been formed by hundreds of users over hundreds of endpoints.},
author = {Ferr{\'{e}}, S{\'{e}}bastien},
doi = {10.3233/SW-150208},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/SPARKLIS.pdf:pdf},
issn = {22104968},
journal = {Semantic Web},
keywords = {SPARQL endpoint,Semantic search,faceted search,natural language,query builder},
number = {3},
pages = {405--418},
title = {{Sparklis: An expressive query builder for SPARQL endpoints with guidance in natural language}},
volume = {8},
year = {2017}
}
@article{Freya12,
author = {Damljanovic, Danica and Agatonovic, Milan and Cunningham, Hamish},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/FREYA.pdf:pdf},
journal = {Eswc},
keywords = {clarification dialogs,learning,natural language interfaces,ontologies,question-answering},
pages = {125--138},
title = {{FREyA : An Interactive Way of Querying Linked}},
year = {2011}
}
@inproceedings{Querix12,
address = {Athens, GA},
author = {Kaufmann, Esther and Bernstein, Abraham and Zumstein, Renato},
booktitle = {In proceedings of the 5th International Semantic Web Conference (ISWC 2006)},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/Kaufmann{\_}Querix{\_}Demo{\_}ISWC2006.pdf:pdf},
number = {November},
pages = {5--6},
title = {{Querix: A Natural Language Interface to Query Ontologies Based on Clarification Dialogs}},
year = {2006}
}

@article{autosparql12,
abstract = {An advantage of Semantic Web standards like RDF and OWL is their flexibility in modifying the structure of a knowledge base. To turn this flexibility into a practical advantage, it is of high importance to have tools and methods, which offer similar flexibility in exploring information in a knowledge base. This is closely related to the ability to easily formulate queries over those knowledge bases. We explain benefits and drawbacks of existing techniques in achieving this goal and then present the QTL algorithm, which fills a gap in research and practice. It uses supervised machine learning and allows users to ask queries without knowing the schema of the underlying knowledge base beforehand and without expertise in the SPARQL query language. We then present the AutoSPARQL user interface, which implements an active learning approach on top of QTL. Finally, we evaluate the approach based on a benchmark data set for question answering over Linked Data.},
author = {Lehmann, Jens and B{\"{u}}hmann, Lorenz},
doi = {10.1007/978-3-642-21034-1_5},
file = {:Users/christineadika/Desktop/Desktop/litreview/autosparql{\_}eswc.pdf:pdf},
isbn = {9783642210334},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 1},
pages = {63--79},
pmid = {2680903},
title = {{AutoSPARQL: Let users query your knowledge base}},
volume = {6643 LNCS},
year = {2011}
}
@article{panto12,
abstract = {Providing a natural language interface to ontologies will not only offer ordinary users the convenience of acquiring needed information from ontologies, but also expand the influence of ontologies and the semantic web consequently. This paper presents PANTO, a Portable nAtural laNguage inTerface to Ontologies, which accepts generic natural language queries and outputs SPARQL queries. Based on a special consideration on nominal phrases, it adopts a triple-based data model to interpret the parse trees output by an off-the-shelf parser. Complex modifications in natural language queries such as negations, superlative and comparative are investigated. The experiments have shown that PANTO provides state-of-the-art results.},
author = {Wang, Chong and Xiong, Miao and Zhou, Qi and Yu, Yong},
doi = {10.1007/978-3-540-72667-8_34},
file = {:Users/christineadika/Desktop/Desktop/litreview/chatbot/Wang2007{\_}Chapter{\_}PANTOAPortableNaturalLanguageI.pdf:pdf},
isbn = {978-3-540-72666-1},
issn = {03029743},
journal = {The Semantic Web: Research and Applications},
pages = {473--487},
title = {{PANTO: A Portable Natural Language Interface to Ontologies}},
url = {http://link.springer.com/10.1007/978-3-540-72667-8{\_}34},
year = {2007}
}
@inproceedings{Yahya2012,
address = {Deanna12},
author = {Yahya, Mohamed and Berberich, Klaus and Elbassuoni, Shady},
booktitle = {EMNLP},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/DEANNA.pdf:pdf},
number = {July},
pages = {379--390},
title = {{Natural Language Questions for the Web of Data}},
year = {2012}
}
@inproceedings{Casia12,
author = {He, Shizhu and Zhang, Yuanzhe and Liu, Kang and Zhao, Jun},
booktitle={CLEF},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/CLEF2014wn-QA-ShizhuEt2014.pdf:pdf},
keywords = {linked data,markov logic network,question answering},
number = {61272332},
pages = {1249--1259},
title = {{CASIA@V2: A MLN-based Question Answering System over Linked Data}},
year={2014}
}

@article{Kextractor12,
author = {Tatu, Marta and Balakrishna, Mithun and Werner, Steven and Erekhinskaya, Tatiana and Moldovan, Dan},
doi = {10.1109/ICSC.2016.29},
file = {:Users/christineadika/Desktop/Desktop/litreview/tatu2016 (1).pdf:pdf},
isbn = {9781509006618},
journal = {Proceedings - 2016 IEEE 10th International Conference on Semantic Computing, ICSC 2016},
keywords = {Automatic Knowledge Extraction,Natural Language Processing (NLP),Resource Description Framework (RDF),SPARQL Interface},
pages = {396--399},
title = {{Automatic Extraction of Actionable Knowledge}},
year = {2016}
}
@article{Marneffe2015,
abstract = {PURPOSE: Normal neonates and many adults after abnormal visual development have directional preferences for visual stimulus motions; i.e., they give better responses for optokinetic nystagmus (OKN) and visually evoked potentials (VEPs) in one direction than to those in the opposite direction. The authors tested whether the VEP responses were asymmetrical because of abnormal eye movements. METHODS: VEPs were recorded from the visual cortices of five macaque monkeys: one normal, one neonate, and three reared with alternating monocular occlusion (AMO). They were lightly anesthetized, followed by paralysis to prevent eye movements. They then had "jittered" vertical grating patterns presented in their visual fields. The steady state VEPs were analyzed with discrete Fourier transforms to obtain the amplitudes and phases of the asymmetries. RESULTS: The normal, control monkey had small, insignificant amplitudes of its asymmetrical Fourier component and random phases that were not 180 degrees out of phase across the left and right eyes. The neonatal monkey and the AMO monkeys all had large, significant asymmetries that were approximately 180 degrees out of phase between the left and right eyes. CONCLUSIONS: The neonate and abnormally reared monkeys continued to have asymmetrical responses even after their eyes were paralyzed. Therefore, eye movements cannot be the source of the asymmetrical amplitudes of the VEPs, and the visual cortex is at least one source responsible for asymmetries observed in neonates and adults reared under abnormal visual inputs.},
author = {Marneffe, Marie-catherine De and Manning, Christopher D},
doi = {10.1.1.180.3691},
file = {:Users/christineadika/Desktop/Desktop/litreview/dependencies{\_}manual.pdf:pdf},
isbn = {1872-9142 (Electronic)$\backslash$r0161-5890 (Linking)},
issn = {01460404},
journal = {20090110 Httpnlp Stanford},
number = {September},
pages = {1--22},
pmid = {10476815},
title = {{Stanford typed dependencies manual}},
url = {http://nlp.stanford.edu/downloads/dependencies{\_}manual.pdf},
volume = {40},
year = {2015}
}

@article{ontologysparql12,
abstract = {OBJECTIVES$\backslash$nThe aim of this study was to discover the public's attitude and views towards privacy in health care. This is a part of a larger project which aims to gain an insight into what kind of privacy is needed and develop technical measures to provide such privacy. $\backslash$n$\backslash$nMETHODS$\backslash$nThe study was a two-stage process which combined qualitative and quantitative research. Stage One of the study comprised arranging and facilitating focus groups while in Stage Two we conducted a social survey. $\backslash$n$\backslash$nMEASUREMENTS$\backslash$nWe measured attitudes towards privacy, medical research and consent; privacy concern about sharing one's health information for research; privacy concern about the possibility that some specific information from medical records could be linked to the patient's name in a situation that was not related to medical treatment. $\backslash$n$\backslash$nRESULTS$\backslash$nThe results of the study revealed both great support for medical research (98{\%}), and concern about privacy of health information (66{\%}). Participants prefer to be asked for their permission before their health information is used for any purpose other than medical treatment (92{\%}), and they would like to know the organisation and details of the research before allowing the use of their health records (83{\%}). Age, level of education, place of birth and employment status are most strongly associated with privacy concerns. The study showed that there are some particularly sensitive issues and there is a concern (42–60{\%}) about any possibility of linking these kinds of data to the patient's name in a situation that is not related to medical treatment. Such issues include sexually transmitted diseases, abortions and infertility, family medical history/genetic disorders, mental illness, drug/alcohol related incidents, lists of previous operations/procedures/dates and current medications. $\backslash$n$\backslash$nCONCLUSIONS$\backslash$nParticipants believe they should be asked for permission before their health information is used for any purpose other than medical treatment. However, consent and privacy concerns are not necessary related. Assuring individuals that their personal health information is de-identified reduces their concern about the necessity of consent for releasing health information for research purposes, but many people are not aware that removing their names and other direct identifiers from medical records does not guarantee full privacy protection for their health information. Privacy concerns decrease as extra security measures are introduced to protect privacy. Therefore, instead of “tailoring concern” as proposed by Willison [1] we suggest improving privacy protection of personal information by introducing additional security measures in data publishing.},
author = {Sander, Malte and Waltinger, Ulli and Roshchin, Mikhail and Runkler, Thomas},
doi = {10.1016/j.ijmedinf.2012.01.005},
file = {:Users/christineadika/Desktop/Desktop/litreview/45bee9bc2a5b5fc06f0bc9d29b9028fbaa56.pdf:pdf},
isbn = {9781577356967},
issn = {13865056},
journal = {2014 AAAI Fall Symposium Ontology-Based},
keywords = {AAAI Technical Report FS-14-06},
pages = {42--48},
title = {{Ontology-Based Translation of Natural Language Queries to SPARQL}},
year = {2014}
}
@article{review1,
abstract = {The need to query information content available in various formats including structured and unstructured data (text in natural language, semi-structured Web documents, structured RDF data in the semantic Web, etc.) has become increasingly important. Thus, Question Answering Systems (QAS) are essential to satisfy this need. QAS aim at satisfying users who are looking to answer a specific question in natural language. In this paper we survey various QAS. We give also statistics and analysis. This can clear the way and help researchers to choose the appropriate solution to their issue. They can see the insufficiency, so that they can propose new systems for complex queries. They can also adapt or reuse QAS techniques for specific research issues.},
author = {Bouziane, Abdelghani and Bouchiha, Djelloul and Doumi, Noureddine and Malki, Mimoun},
doi = {10.1016/j.procs.2015.12.005},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/review1.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Information Retrieval,Natural Language Processing (NLP),Question Answering System (QAS),SPARQL,Semantic Web},
number = {Awict},
pages = {366--375},
publisher = {Elsevier Masson SAS},
title = {{Question Answering Systems: Survey and Trends}},
url = {http://dx.doi.org/10.1016/j.procs.2015.12.005},
volume = {73},
year = {2015}
}
@article{review2,
author = {Cimiano, Philipp and Bielefeld, Universit{\"{a}}t},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/review2.pdf:pdf},
journal = {Semantic Web},
keywords = {natural language,ontology,question answering survey,semantic web},
number = {2},
pages = {125--155},
title = {{Is Question Answering fit for the Semantic Web ?: a Survey .}},
volume = {2},
year = {2011}
}

@misc{Sparql12,
author = {{SPARQL Working Group}},
title = {{SPARQL Query Language for RDF}},
url = {http://www.w3.org/TR/rdf-sparql-query/},
Accessed = {2018-12-12},
year = {2013}
}
@article{Stoilos2005,
abstract = {Ontologies are today a key part of every knowledge based system. They provide a source of shared and precisely defined terms, resulting in system interoperability by knowledge sharing and reuse. Unfortunately, the variety of ways that a domain can be conceptualized results in the creation of different ontologies with contradicting or overlapping parts. For this reason ontologies need to be brought into mutual agreement (aligned). One important method for ontology alignment is the comparison of class and property names of ontologies using string-distance metrics. Today quite a lot of such metrics exist in literature. But all of them have been initially developed for different applications and fields, resulting in poor performance when applied in this new domain. In the current paper we present a new string metric for the comparison of names which performs better on the process of ontology alignment as well as to many other field matching problems.},
author = {Stoilos, Giorgos and Stamou, Giorgos and Kollias, Stefanos},
doi = {10.1007/11574620_45},
file = {:Users/christineadika/Library/Application Support/Mendeley Desktop/Downloaded/Stoilos, Stamou, Kollias - 2005 - A string metric for ontology alignment.pdf:pdf},
isbn = {3540297545},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {624--637},
title = {{A string metric for ontology alignment}},
volume = {3729 LNCS},
year = {2005}
}
@article{quad9,
abstract = {The past years have seen a growing amount of research on question answering (QA) over Semantic Web data, shaping an interaction paradigm that allows end users to profit from the expressive power of Semantic Web standards while, at the same time, hiding their complexity behind an intuitive and easy-to-use interface. On the other hand, the growing amount of data has led to a heterogeneous data landscape where QA systems struggle to keep up with the volume, variety and veracity of the underlying knowledge.},
author = {Usbeck, Ricardo and Gusmita, Ria Hari and Saleem, Muhammad and Ngomo, Axel Cyrille Ngonga},
doi = {10.1007/978-3-319-69146-6_6},
file = {:Users/christineadika/Desktop/papers{\_}NL{\_}TO{\_}SPARQL/quad9.pdf:pdf},
isbn = {9783319691459},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
pages = {58--64},
title = {{9th challenge on question answering over linked data (QALD-9)}},
volume = {2241},
year = {2018}
}
@inproceedings{john2011,
abstract = {There are a large number of ontologies currently available on the Semantic Web. However, in order to exploit them within natural language processing applications, more linguistic information than can be represented in current Semantic Web standards is required. Further, there are a large number of lexical resources available representing a wealth of linguistic information, but this data exists in various formats and is difficult to link to ontologies and other resources. We present a model we call lemon (Lexicon Model for Ontologies) that supports the sharing of terminological and lexicon resources on the Semantic Web as well as their linking to the existing semantic representations provided by ontologies. We demonstrate that lemon can succinctly represent existing lexical resources and in combination with standard NLP tools we can easily generate new lexica for domain ontologies according to the lemon model. We demonstrate that by combining generated and existing lexica we can collaboratively develop rich lexical descriptions of ontology entities. We also show that the adoption of Semantic Web standards can provide added value for lexicon models by supporting a rich axiomatization of linguistic categories that can be used to constrain the usage of the model and to perform consistency checks. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
author = {McCrae, John and Spohr, Dennis and Cimiano, Philipp},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-21034-1_17},
file = {:Users/christineadika/Desktop/McCrae2011{\_}Chapter{\_}LinkingLexicalResourcesAndOnto.pdf:pdf},
isbn = {9783642210334},
issn = {03029743},
pages = {245--259},
title = {{Linking lexical resources and ontologies on the semantic web with lemon}},
volume = {6643 LNCS},
year = {2011}
}
@article{walter2013,
author = {Walter, Sebastian and Unger, Christina and Cimiano, Philipp},
doi = {10.1007/978-3-642-38824-8_9},
file = {:Users/christineadika/Desktop/walter2013.pdf:pdf},
isbn = {9783642388231},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {corpus-based approach,lemon,ontology lexicalization},
pages = {102--113},
title = {{A corpus-based approach for the induction of ontology lexica}},
volume = {7934 LNCS},
year = {2013}
}
@article{g2018,
author = {Zhao, Dongyan and Zou, Lei and Wang, Haixun and Yu, Jeffrey Xu and Hu, Sen},
doi = {10.1109/tkde.2017.2766634},
file = {:Users/christineadika/Desktop/TKDE-final.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
number = {5},
pages = {824--837},
title = {{Answering Natural Language Questions by Subgraph Matching over Knowledge Graphs}},
volume = {30},
year = {2017}

}
@article{wera2018,
abstract = {The recent advance in deep learning and semantic parsing has significantly improved the translation accuracy of natural language questions to structured queries. However, further improvement of the existing approaches turns out to be quite challenging. Rather than solely relying on algorithmic innovations, in this work, we introduce DialSQL, a dialogue-based structured query generation framework that leverages human intelligence to boost the performance of existing algorithms via user interaction. DialSQL is capable of identifying potential errors in a generated SQL query and asking users for validation via simple multi-choice questions. User feedback is then leveraged to revise the query. We design a generic simulator to bootstrap synthetic training dialogues and evaluate the performance of DialSQL on the WikiSQL dataset. Using SQLNet as a black box query generation tool, DialSQL improves its performance from 61.3{\%} to 69.0{\%} using only 2.4 validation questions per dialogue.},
author = {Gur, Izzeddin and Yavuz, Semih and Su, Yu and Yan, Xifeng},
file = {:Users/christineadika/Desktop/review{\_}corrections/REVIEW6.pdf:pdf},
journal = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics},
pages = {1339--1349},
title = {{DialSQL: Dialogue Based Structured Query Generation}},
url = {https://www.aclweb.org/anthology/papers/P/P18/P18-1124/},
year = {2018}
}
@inproceedings{Yu2018,
abstract = {Most existing studies in text-to-SQL tasks do not require generating complex SQL queries with multiple clauses or sub-queries, and generalizing to new, unseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network to address the complex and cross-domain text-to-SQL generation task. SyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL generation path history and table-aware column attention encoders. We evaluate SyntaxSQLNet on the Spider text-to-SQL task, which contains databases with multiple tables and complex SQL queries with multiple SQL clauses and nested queries. We use a database split setting where databases in the test set are unseen during training. Experimental results show that SyntaxSQLNet can handle a significantly greater number of complex SQL examples than prior work, outperforming the previous state-of-the-art model by 7.3{\%} in exact matching accuracy. We also show that SyntaxSQLNet can further improve the performance by an additional 7.5{\%} using a cross-domain augmentation method, resulting in a 14.8{\%} improvement in total. To our knowledge, we are the first to study this complex and cross-domain text-to-SQL task.},
archivePrefix = {arXiv},
arxivId = {1810.05237},
author = {Yu, Tao and Yasunaga, Michihiro and Yang, Kai and Zhang, Rui and Wang, Dongxu and Li, Zifan and Radev, Dragomir},
booktitle = {In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
eprint = {1810.05237},
file = {:Users/christineadika/Desktop/review{\_}corrections/REVIEW4.pdf:pdf},
keywords = {semad2019},
pages = {1653--1663},
title = {{SyntaxSQLNet: Syntax Tree Networks for Complex and Cross-DomainText-to-SQL Task}},
url = {http://arxiv.org/abs/1810.05237},
year = {2018}
}
@inproceedings{sema2015,
abstract = {An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches over the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems which already incorporate known techniques such as dropout. Our ensemble model using different attention architectures has established a new state-of-the-art result in the WMT'15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker.},
author = {Ahmad, Shahzaib and Hunt, Beverley J.},
booktitle = {In Proceedings of the 2015 Conference on Empirical Meth- ods in Natural Language Processingn},
doi = {10.1007/978-3-319-28308-1_29},
file = {:Users/christineadika/Desktop/review{\_}corrections/REVIEW11.pdf:pdf},
isbn = {9783319283081},
number = {September},
pages = {1412--1421},
title = {{Effective Approaches to Attention-based Neural Machine Translation}},
year = {2015}
}
@inproceedings{sema201,
abstract = {We present an approach to rapidly and easily build natural language interfaces to databases for new domains, whose performance improves over time based on user feedback, and requires minimal intervention. To achieve this, we adapt neural sequence models to map utterances directly to SQL with its full expressivity, bypassing any intermediate meaning representations. These models are immediately deployed online to solicit feedback from real users to flag incorrect queries. Finally, the popularity of SQL facilitates gathering annotations for incorrect predictions using the crowd, which is directly used to improve our models. This complete feedback loop, without intermediate representations or database specific engineering, opens up new ways of building high quality semantic parsers. Experiments suggest that this approach can be deployed quickly for any new target domain, as we show by learning a semantic parser for an online academic database from scratch.},
archivePrefix = {arXiv},
arxivId = {1704.08760},
author = {Iyer, Srinivasan and Konstas, Ioannis and Cheung, Alvin and Krishnamurthy, Jayant and Zettlemoyer, Luke},
booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics},
eprint = {1704.08760},
file = {:Users/christineadika/Desktop/neural{\_}network{\_}papers/1704.08760.pdf:pdf},
title = {{Learning a Neural Semantic Parser from User Feedback}},
url = {http://arxiv.org/abs/1704.08760},
year = {2017}
}
@article{noma2018,
abstract = {Thanks to the development of the Semantic Web, a lot of new structured data has become available on the Web in the form of knowledge bases (KBs). Making this valuable data accessible and usable for end-users is one of the main goals of Question Answering (QA) over KBs. Most current QA systems query one KB, in one language (namely English). The existing approaches are not designed to be easily adaptable to new KBs and languages. We first introduce a new approach for translating natural language questions to SPARQL queries. It is able to query several KBs simultaneously, in different languages, and can easily be ported to other KBs and languages. In our evaluation, the impact of our approach is proven using 5 different well-known and large KBs: Wikidata, DBpedia, MusicBrainz, DBLP and Freebase as well as 5 different languages namely English, German, French, Italian and Spanish. Second, we show how we integrated our approach, to make it easily accessible by the research community and by end-users. To summarize, we provided a conceptional solution for multilingual, KB-agnostic Question Answering over the Semantic Web. The provided first approximation validates this concept.},
archivePrefix = {arXiv},
arxivId = {1803.00832},
author = {Diefenbach, Dennis and Both, Andreas and Singh, Kamal and Maret, Pierre},
eprint = {1803.00832},
file = {:Users/christineadika/Desktop/review{\_}corrections/REVIEW7.pdf:pdf},
journal = {Semantic Web},
keywords = {multilinguality,portability,qald,question answering,simplequestions},
number = {0},
pages = {1-15},
title = {{Towards a Question Answering System over the Semantic Web}},
url = {http://arxiv.org/abs/1803.00832},
volume = {0},
year = {2018}
}
@inproceedings{sema2019,
abstract = {With the rapid growth of knowledge bases (KBs) on the web, how to take full advantage of them becomes increasingly important. Question answering over knowledge base (KB-QA) is one of the promising approaches to access the substantial knowledge. Meanwhile, as the neural network-based (NN-based) methods develop, NN-based KB-QA has already achieved impressive results. However, previous work did not put more emphasis on question representation, and the question is converted into a fixed vector regardless of its candidate answers. This simple representation strategy is not easy to express the proper information in the question. Hence, we present an end-to-end neural network model to represent the questions and their corresponding scores dynamically according to the various candidate answer aspects via cross-attention mechanism. In addition, we leverage the global knowledge inside the underlying KB, aiming at integrating the rich KB information into the representation of the answers. As a result, it could alleviates the out-of-vocabulary (OOV) problem, which helps the cross-attention model to represent the question more precisely. The experimental results on WebQuestions demonstrate the effectiveness of the proposed approach.},
author = {Hao, Yanchao and Zhang, Yuanzhe and Liu, Kang and He, Shizhu and Liu, Zhanyi and Wu, Hua and Zhao, Jun},
booktitle = {In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics},
doi = {10.18653/v1/p17-1021},
file = {:Users/christineadika/Desktop/neural{\_}network{\_}papers/ACL2017-Hao.pdf:pdf},
pages = {221--231},
title = {{An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge}},
year = {2017}
}
@inproceedings{sema2019,
abstract = {With the rapid growth of knowledge bases (KBs) on the web, how to take full advantage of them becomes increasingly important. Question answering over knowledge base (KB-QA) is one of the promising approaches to access the substantial knowledge. Meanwhile, as the neural network-based (NN-based) methods develop, NN-based KB-QA has already achieved impressive results. However, previous work did not put more emphasis on question representation, and the question is converted into a fixed vector regardless of its candidate answers. This simple representation strategy is not easy to express the proper information in the question. Hence, we present an end-to-end neural network model to represent the questions and their corresponding scores dynamically according to the various candidate answer aspects via cross-attention mechanism. In addition, we leverage the global knowledge inside the underlying KB, aiming at integrating the rich KB information into the representation of the answers. As a result, it could alleviates the out-of-vocabulary (OOV) problem, which helps the cross-attention model to represent the question more precisely. The experimental results on WebQuestions demonstrate the effectiveness of the proposed approach.},
author = {Hao, Yanchao and Zhang, Yuanzhe and Liu, Kang and He, Shizhu and Liu, Zhanyi and Wu, Hua and Zhao, Jun},
booktitle = {In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics},
doi = {10.18653/v1/p17-1021},
file = {:Users/christineadika/Desktop/neural{\_}network{\_}papers/ACL2017-Hao.pdf:pdf},
pages = {221--231},
title = {{An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge}},
year = {2017}
}
@article{Bordes2015,
abstract = {Training large-scale question answering systems is complicated because training sources usually cover a small portion of the range of possible questions. This paper studies the impact of multitask and transfer learning for simple question answering; a setting for which the reasoning required to answer is quite easy, as long as one can retrieve the correct evidence given a question, which can be difficult in large-scale conditions. To this end, we introduce a new dataset of 100k questions that we use in conjunction with existing benchmarks. We conduct our study within the framework of Memory Networks (Weston et al., 2015) because this perspective allows us to eventually scale up to more complex reasoning, and show that Memory Networks can be successfully trained to achieve excellent performance.},
archivePrefix = {arXiv},
arxivId = {1506.02075},
author = {Bordes, Antoine and Usunier, Nicolas and Chopra, Sumit and Weston, Jason},
eprint = {1506.02075},
file = {:Users/christineadika/Desktop/review{\_}corrections/REVIEW12.pdf:pdf},
journal = {CoRR},
title = {{Large-scale Simple Question Answering with Memory Networks}},
url = {http://arxiv.org/abs/1506.02075},
year = {2015}
}
@article{large2017,
abstract = {{\textcopyright} Springer International Publishing AG 2017. Being able to access knowledge bases in an intuitive way has been an active area of research over the past years. In particular, several question answering (QA) approaches which allow to query RDF datasets in natural language have been developed as they allow end users to access knowledge without needing to learn the schema of a knowledge base and learn a formal query language. To foster this research area, several training datasets have been created, e.g. in the QALD (Question Answering over Linked Data) initiative. However, existing datasets are insufficient in terms of size, variety or complexity to apply and evaluate a range of machine learning based QA approaches for learning complex SPARQL queries. With the provision of the Large-Scale Complex Question Answering Dataset (LC-QuAD), we close this gap by providing a dataset with 5000 questions and their corresponding SPARQL queries over the DBpedia dataset. In this article, we describe the dataset creation process and how we ensure a high variety of questions, which should enable to assess the robustness and accuracy of the next generation of QA systems for knowledge graphs.},
author = {Trivedi, Priyansh and Maheshwari, Gaurav and Dubey, Mohnish and Lehmann, Jens},
doi = {10.1007/978-3-319-68204-4_22},
file = {:Users/christineadika/Desktop/review{\_}corrections/REVIEW13.pdf:pdf},
isbn = {9783319682037},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {210--218},
title = {{LC-QuAD: A corpus for complex question answering over knowledge graphs}},
volume = {10588 LNCS},
year = {2017}
}
@article{sema1997,
author = {{Hochreiter, Sepp and Schmidhuber}, J¨urgen},
file = {:Users/christineadika/Desktop/review{\_}corrections/REVIEW10.pdf:pdf},
journal = {Neural Computation},
number = {8},
pages = {1--32},
title = {{Long Short-Term Memory}},
volume = {9},
year = {1997}
}
@article{quad92018,
abstract = {The past years have seen a growing amount of research on question answering (QA) over Semantic Web data, shaping an interaction paradigm that allows end users to profit from the expressive power of Semantic Web standards while, at the same time, hiding their complexity behind an intuitive and easy-to-use interface. On the other hand, the growing amount of data has led to a heterogeneous data landscape where QA systems struggle to keep up with the volume, variety and veracity of the underlying knowledge.},
author = {Usbeck, Ricardo and Gusmita, Ria Hari and Saleem, Muhammad and Ngomo, Axel Cyrille Ngonga},
doi = {10.1007/978-3-319-69146-6_6},
file = {:Users/christineadika/Desktop/review{\_}corrections/REVIEW9.pdf:pdf},
isbn = {9783319691459},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
pages = {58--64},
title = {{9th challenge on question answering over linked data (QALD-9)}},
volume = {2241},
year = {2018}
}
@article{sema20p,
abstract = {Machine translation is going through a radical revolution, driven by the explosive development of deep learning techniques using Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN). In this paper, we consider a special case in machine translation problems, targeting to convert natural language into Structured Query Language (SQL) for data retrieval over relational database. Although generic CNN and RNN learn the grammar structure of SQL when trained with sufficient samples, the accuracy and training efficiency of the model could be dramatically improved, when the translation model is deeply integrated with the grammar rules of SQL. We present a new encoder-decoder framework, with a suite of new approaches, including new semantic features fed into the encoder, grammar-aware states injected into the memory of decoder, as well as recursive state management for sub-queries. These techniques help the neural network better focus on understanding semantics of operations in natural language and save the efforts on SQL grammar learning. The empirical evaluation on real world database and queries show that our approach outperform state-of-the-art solution by a significant margin.},
author = {Cai, Ruichu and Xu, Boyan and Zhang, Zhenjie and Yang, Xiaoyan and Li, Zijian and Liang, Zhihao},
file = {:Users/christineadika/Desktop/0553.pdf:pdf},
isbn = {9780999241127},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Machine Learning: Deep Learning,Natural Language Processing: NLP Applications and},
pages = {3977--3983},
title = {{An encoder-decoder framework translating natural language to database queries}},
volume = {2018-July},
year = {2018}
}
@article{Nomas123,
abstract = {Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the "order-matters" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited. In this paper, we propose a novel approach, i.e., SQLNet, to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular, we employ a sketch-based approach where the sketch contains a dependency graph so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition, we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques, we show that SQLNet can outperform the prior art by 9{\%} to 13{\%} on the WikiSQL task.},
archivePrefix = {arXiv},
arxivId = {1711.04436},
author = {Xu, Xiaojun and Liu, Chang and Song, Dawn},
eprint = {1711.04436},
file = {:Users/christineadika/Desktop/review{\_}corrections/REVIEW5.pdf:pdf},
journal = {. CoRR},
pages = {1--13},
title = {{SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning}},
url = {http://arxiv.org/abs/1711.04436},
year = {2017}
}









